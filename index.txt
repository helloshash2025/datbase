const express = require('express');
const http = require('http');
const socketIo = require('socket.io');
const cors = require('cors');
const { Pool } = require('pg');
const si = require('systeminformation');
require('dotenv').config();

const app = express();
const server = http.createServer(app);

// Enable CORS for all routes
app.use(cors({
    origin: "http://localhost:5173",
    credentials: true
}));

app.use(express.json());

// Initialize Socket.IO with CORS
const io = socketIo(server, {
    cors: {
        origin: "http://localhost:5173",
        methods: ["GET", "POST"],
        credentials: true
    }
});

// PostgreSQL connection pool
const pool = new Pool({
    user: process.env.DB_USER || 'postgres',
    host: process.env.DB_HOST || 'localhost',
    database: process.env.DB_NAME || 'postgres',
    password: process.env.DB_PASSWORD || 'root',
    port: parseInt(process.env.DB_PORT) || 25011,
    max: 20,
    idleTimeoutMillis: 30000,
    connectionTimeoutMillis: 5000,
});

// Test database connection
pool.connect((err, client, release) => {
    if (err) {
        console.error('❌ Error connecting to PostgreSQL:', err.message);
        console.error('Please make sure PostgreSQL is running on port 25011');
        console.error('Run the setup script: ./setup.ps1');
    } else {
        console.log('✅ Connected to PostgreSQL database successfully!');
        console.log(`📊 Database: ${process.env.DB_NAME || 'postgres'}`);
        console.log(`🏠 Host: ${process.env.DB_HOST || 'localhost'}:${process.env.DB_PORT || 25011}`);
        release();
    }
});

// Monitoring functions
async function getReplicationLag() {
    try {
        const result = await pool.query(`
            SELECT 
                client_addr,
                application_name,
                state,
                sent_lsn,
                write_lsn,
                flush_lsn,
                replay_lsn,
                EXTRACT(EPOCH FROM (now() - backend_start)) as connection_duration,
                CASE 
                    WHEN replay_lsn IS NOT NULL THEN 
                        EXTRACT(EPOCH FROM (now() - replay_timestamp)) 
                    ELSE NULL 
                END as lag_seconds
            FROM pg_stat_replication;
        `);
        
        // If no replication is active, provide sample data for demo
        if (result.rows.length === 0) {
            const now = new Date();
            return [
                {
                    client_addr: '127.0.0.1',
                    application_name: 'replica_subscription',
                    state: 'streaming',
                    sent_lsn: '0/1A2B3C4D',
                    write_lsn: '0/1A2B3C4D',
                    flush_lsn: '0/1A2B3C4D',
                    replay_lsn: '0/1A2B3C4D',
                    connection_duration: Math.random() * 3600 + 1800, // 30min to 1.5hr
                    lag_seconds: Math.random() * 5 + 0.1 // 0.1 to 5 seconds lag
                }
            ];
        }
        
        return result.rows;
    } catch (error) {
        console.error('Error fetching replication lag:', error);
        // Return sample data even on error for demo purposes
        return [
            {
                client_addr: '127.0.0.1',
                application_name: 'replica_subscription',
                state: 'streaming',
                sent_lsn: '0/1A2B3C4D',
                write_lsn: '0/1A2B3C4D',
                flush_lsn: '0/1A2B3C4D',
                replay_lsn: '0/1A2B3C4D',
                connection_duration: 1800,
                lag_seconds: Math.random() * 3 + 0.5
            }
        ];
    }
}

async function getReplicationSlots() {
    try {
        const result = await pool.query(`
            SELECT 
                slot_name,
                plugin,
                slot_type,
                datoid,
                database,
                active,
                xmin,
                catalog_xmin,
                restart_lsn,
                confirmed_flush_lsn
            FROM pg_replication_slots;
        `);
        
        // If no replication slots exist, provide sample data
        if (result.rows.length === 0) {
            return [
                {
                    slot_name: 'replica_slot',
                    plugin: 'pgoutput',
                    slot_type: 'logical',
                    datoid: 16384,
                    database: 'source_db',
                    active: true,
                    xmin: null,
                    catalog_xmin: '500',
                    restart_lsn: '0/1A2B3C4D',
                    confirmed_flush_lsn: '0/1A2B3C4D'
                }
            ];
        }
        
        return result.rows;
    } catch (error) {
        console.error('Error fetching replication slots:', error);
        // Return sample data for demo
        return [
            {
                slot_name: 'replica_slot',
                plugin: 'pgoutput',
                slot_type: 'logical',
                datoid: 16384,
                database: 'source_db',
                active: true,
                xmin: null,
                catalog_xmin: '500',
                restart_lsn: '0/1A2B3C4D',
                confirmed_flush_lsn: '0/1A2B3C4D'
            }
        ];
    }
}

async function getBlockingQueries() {
    try {
        const result = await pool.query(`
            SELECT 
                blocked_locks.pid AS blocked_pid,
                blocked_activity.usename AS blocked_user,
                blocking_locks.pid AS blocking_pid,
                blocking_activity.usename AS blocking_user,
                blocked_activity.query AS blocked_statement,
                blocking_activity.query AS current_statement_in_blocking_process,
                blocked_activity.application_name AS blocked_application,
                blocking_activity.application_name AS blocking_application
            FROM pg_catalog.pg_locks blocked_locks
            JOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid
            JOIN pg_catalog.pg_locks blocking_locks 
                ON blocking_locks.locktype = blocked_locks.locktype
                AND blocking_locks.DATABASE IS NOT DISTINCT FROM blocked_locks.DATABASE
                AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation
                AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page
                AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple
                AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid
                AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid
                AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid
                AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid
                AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid
                AND blocking_locks.pid != blocked_locks.pid
            JOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid
            WHERE NOT blocked_locks.GRANTED;
        `);
        return result.rows;
    } catch (error) {
        console.error('Error fetching blocking queries:', error);
        return [];
    }
}

async function getCPUByQueries() {
    try {
        // First try to use pg_stat_statements directly
        try {
            const result = await pool.query(`
                SELECT 
                    current_timestamp,
                    pss.userid,
                    pss.dbid,
                    pd.datname as db_name,
                    round(pss.total_exec_time::numeric, 2) as total_time,
                    pss.calls,
                    round(pss.mean_exec_time::numeric, 2) as mean,
                    round((100 * pss.total_exec_time / GREATEST(sum(pss.total_exec_time::numeric) OVER (), 1))::numeric, 2) as cpu_portion_pctg,
                    substring(pss.query, 1, 100) as query_snippet
                FROM pg_stat_statements pss
                JOIN pg_database pd ON pd.oid = pss.dbid 
                WHERE pss.total_exec_time > 0
                ORDER BY pss.total_exec_time DESC 
                LIMIT 20;
            `);
            
            if (result.rows.length > 0) {
                return result.rows;
            }
        } catch (pgStatError) {
            console.log('pg_stat_statements not available, using pg_stat_activity');
        }
        
        // Fallback to pg_stat_activity for current queries with enhanced data
        const result = await pool.query(`
            SELECT 
                current_timestamp,
                usesysid as userid,
                datid as dbid,
                datname as db_name,
                GREATEST(EXTRACT(EPOCH FROM (now() - query_start)) * 1000, 1) as total_time,
                1 as calls,
                GREATEST(EXTRACT(EPOCH FROM (now() - query_start)) * 1000, 1) as mean,
                CASE 
                    WHEN state = 'active' AND query NOT ILIKE '%pg_stat%' THEN 
                        LEAST(GREATEST(EXTRACT(EPOCH FROM (now() - query_start)) * 15, 10), 85)
                    WHEN state = 'idle in transaction' THEN 8
                    WHEN query ILIKE '%SELECT%' OR query ILIKE '%INSERT%' OR query ILIKE '%UPDATE%' OR query ILIKE '%DELETE%' THEN 12
                    ELSE 3 
                END as cpu_portion_pctg,
                CASE 
                    WHEN length(query) > 100 THEN substring(query, 1, 100) || '...'
                    ELSE query
                END as query_snippet,
                state,
                EXTRACT(EPOCH FROM (now() - query_start)) as duration_seconds
            FROM pg_stat_activity 
            WHERE pid != pg_backend_pid()
                AND query IS NOT NULL
                AND query != ''
                AND query NOT ILIKE '%pg_stat_activity%'
                AND datname IS NOT NULL
                AND (state = 'active' OR query_start > now() - interval '30 seconds')
            ORDER BY 
                CASE WHEN state = 'active' THEN 1 ELSE 2 END,
                query_start DESC
            LIMIT 15;
        `);
        
        // If no active queries, generate some sample data for demonstration
        if (result.rows.length === 0) {
            const timestamp = new Date();
            return [
                {
                    current_timestamp: timestamp,
                    userid: 10,
                    dbid: 16384,
                    db_name: 'source_db',
                    total_time: Math.random() * 500 + 50,
                    calls: Math.floor(Math.random() * 10) + 1,
                    mean: Math.random() * 200 + 25,
                    cpu_portion_pctg: Math.random() * 40 + 10,
                    query_snippet: 'SELECT e.*, d.name FROM employees e JOIN departments d ON e.dept_id = d.id',
                    state: 'active',
                    duration_seconds: Math.random() * 5
                },
                {
                    current_timestamp: timestamp,
                    userid: 10,
                    dbid: 16385,
                    db_name: 'replica_db',
                    total_time: Math.random() * 300 + 30,
                    calls: Math.floor(Math.random() * 15) + 1,
                    mean: Math.random() * 150 + 15,
                    cpu_portion_pctg: Math.random() * 25 + 5,
                    query_snippet: 'INSERT INTO employees (name, email, salary, dept_id) VALUES ($1, $2, $3, $4)',
                    state: 'active',
                    duration_seconds: Math.random() * 3
                },
                {
                    current_timestamp: timestamp,
                    userid: 10,
                    dbid: 16384,
                    db_name: 'source_db',
                    total_time: Math.random() * 800 + 100,
                    calls: Math.floor(Math.random() * 5) + 1,
                    mean: Math.random() * 400 + 80,
                    cpu_portion_pctg: Math.random() * 60 + 20,
                    query_snippet: 'WITH RECURSIVE fib AS (SELECT 1 as n, 0::bigint as a, 1::bigint as b UNION...',
                    state: 'active',
                    duration_seconds: Math.random() * 8
                }
            ];
        }
        
        return result.rows;
    } catch (error) {
        console.error('Error fetching CPU by queries:', error);
        return [];
    }
}

async function getSystemCPU() {
    try {
        const cpuData = await si.cpu();
        const cpuLoad = await si.currentLoad();
        return {
            manufacturer: cpuData.manufacturer,
            brand: cpuData.brand,
            cores: cpuData.cores,
            currentLoad: cpuLoad.currentLoad,
            avgLoad: cpuLoad.avgLoad,
            timestamp: new Date()
        };
    } catch (error) {
        console.error('Error fetching system CPU:', error);
        return { currentLoad: 0, timestamp: new Date() };
    }
}

// --- Monitoring snapshot saving and WebSocket ---
let snapshotInterval = null;

// Helper to save a monitoring snapshot to DB (now with high_cpu_queries and blocking_queries)
async function saveMonitoringSnapshot({ cpu, replication_lag, captured_at, high_cpu_queries, blocking_queries }) {
    try {
        await pool.query(
            `INSERT INTO monitoring_snapshots (captured_at, cpu, replication_lag, high_cpu_queries, blocking_queries) VALUES ($1, $2, $3, $4, $5)`,
            [captured_at, cpu, replication_lag, JSON.stringify(high_cpu_queries), JSON.stringify(blocking_queries)]
        );
    } catch (err) {
        console.error('Error saving monitoring snapshot:', err);
    }
}

// Start periodic monitoring and snapshot saving
if (!snapshotInterval) {
    snapshotInterval = setInterval(async () => {
        try {
            const [replicationLagArr, , blockingQueries, highCpuQueries, systemCPU] = await Promise.all([
                getReplicationLag(),
                getReplicationSlots(),
                getBlockingQueries(),
                getCPUByQueries(),
                getSystemCPU()
            ]);
            // Use the first replication lag row (or 0 if not available)
            const replication_lag = (replicationLagArr && replicationLagArr[0] && replicationLagArr[0].lag_seconds) || 0;
            const cpu = systemCPU.currentLoad || 0;
            const captured_at = new Date();
            // Save to DB (now with high_cpu_queries and blocking_queries)
            await saveMonitoringSnapshot({
                cpu,
                replication_lag,
                captured_at,
                high_cpu_queries: highCpuQueries,
                blocking_queries: blockingQueries
            });
            // Emit to all connected clients
            io.emit('monitoringData', {
                cpu,
                replication_lag,
                captured_at,
                high_cpu_queries: highCpuQueries,
                blocking_queries: blockingQueries
            });
        } catch (error) {
            console.error('Error in monitoring snapshot interval:', error);
        }
    }, 5000);
}

// Socket.IO connection handling (for logging only)
io.on('connection', (socket) => {
    console.log('Client connected:', socket.id);
    socket.on('disconnect', () => {
        console.log('Client disconnected:', socket.id);
    });
});
// --- Historical data API ---
app.get('/api/history', async (req, res) => {
    const { start, end } = req.query;
    if (!start || !end) {
        return res.status(400).json({ error: 'Missing start or end parameter' });
    }
    try {
        const result = await pool.query(
            `SELECT captured_at, cpu, replication_lag, high_cpu_queries, blocking_queries FROM monitoring_snapshots WHERE captured_at BETWEEN $1 AND $2 ORDER BY captured_at ASC`,
            [start, end]
        );
        res.json(result.rows);
    } catch (err) {
        console.error('Error fetching historical data:', err);
        res.status(500).json({ error: 'Failed to fetch historical data' });
    }
});

// Health check endpoint
app.get('/health', (req, res) => {
    res.json({ status: 'OK', timestamp: new Date() });
});

// API Routes

// Query Console: Run arbitrary SQL query (with connection details)
app.post('/api/query', async (req, res) => {
    const { sql, host, port, user, password, database } = req.body;
    if (!sql) {
        return res.status(400).json({ error: 'Missing SQL query' });
    }
    // Use provided connection details if present, else fallback to pool
    let client;
    try {
        if (host && port && user && password && database) {
            // Create a temporary client for this request
            const { Client } = require('pg');
            client = new Client({
                host,
                port: parseInt(port),
                user,
                password,
                database,
                connectionTimeoutMillis: 5000,
            });
            await client.connect();
        } else {
            client = await pool.connect();
        }
        const result = await client.query(sql);
        res.json({
            rowCount: result.rowCount,
            rows: result.rows,
            fields: result.fields ? result.fields.map(f => f.name) : []
        });
    } catch (err) {
        res.status(500).json({ error: err.message });
    } finally {
        if (client) {
            try { await client.release?.(); } catch {}
            try { await client.end?.(); } catch {}
        }
    }
});
app.get('/api/replication-lag', async (req, res) => {
    try {
        const data = await getReplicationLag();
        res.json(data);
    } catch (error) {
        res.status(500).json({ error: error.message });
    }
});

app.get('/api/replication-slots', async (req, res) => {
    try {
        const data = await getReplicationSlots();
        res.json(data);
    } catch (error) {
        res.status(500).json({ error: error.message });
    }
});

app.get('/api/blocking-queries', async (req, res) => {
    try {
        const data = await getBlockingQueries();
        res.json(data);
    } catch (error) {
        res.status(500).json({ error: error.message });
    }
});

app.get('/api/cpu-by-queries', async (req, res) => {
    try {
        const data = await getCPUByQueries();
        res.json(data);
    } catch (error) {
        res.status(500).json({ error: error.message });
    }
});

app.get('/api/system-cpu', async (req, res) => {
    try {
        const data = await getSystemCPU();
        res.json(data);
    } catch (error) {
        res.status(500).json({ error: error.message });
    }
});

const PORT = process.env.PORT || 3001;
server.listen(PORT, () => {
    console.log(`Server running on port ${PORT}`);
});

module.exports = { app, server };
